
### 一、数据预处理
- 数据集：使用公开的亚马逊评论数据集（Amazon Review data），选取 Beauty 和 Electronics 两个类别。
- 数据清洗：
  - 移除标题缺失或过长（> 400 字符）的商品。
  - 对用户交互序列去重，并截断至最大长度为15。
- 任务设定：采用“下一项预测”任务，将每个用户序列按 0.8/0.1/0.1 划分为训练集、验证集和测试集。

---

### 二、模型架构与训练
GPT4Rec 是一个生成式推荐框架，分为两个核心组件：

#### 1. 查询生成（Query Generation）
- 模型选择：使用预训练的 GPT-2（117M 参数）作为生成模型。
- 输入格式：将用户历史交互的商品标题拼接成如下提示文本：
  ```
  Previously, the customer has bought:
  <ITEM TITLE 1>. <ITEM TITLE 2>...
  In the future, the customer wants to buy
  ```
- 训练方式：采用对比学习思想，将最后一个商品标题作为生成目标，对 GPT-2 进行微调。
- 多查询生成策略：使用Beam Search 生成多个查询，以捕捉用户兴趣的多样性和不同粒度。

#### 2. 项目检索（Item Retrieval）
- 检索引擎：使用 BM25 作为搜索引擎，根据生成的查询从商品库中检索相关商品。
- 排名策略：对每个查询检索出的结果进行去重与合并，按生成分数排序，确保推荐结果既相关又多样。
- BM25 参数调优：通过网格搜索优化参数 \(k_1\) 和 \(b\)。

---

### 三、实验与评估
#### 评估指标：
- Recall@K：衡量目标商品是否出现在前 K 个推荐中。
- Diversity@K：基于商品类别/品牌的 Jaccard 相似度衡量推荐多样性。
- Coverage@K：衡量推荐结果覆盖用户历史兴趣的程度。

#### 基线模型：
- FM-BPR
- ContentRec
- YouTubeDNN
- BERT4Rec

#### 主要发现：
- GPT4Rec 在 Recall@K 上显著优于所有基线模型（Beauty 提升 75.7%，Electronics 提升 22.2%）。
- 生成多个查询（如生成 K 个查询，每个查询检索一个商品）能同时提升相关性、多样性和兴趣覆盖度。



### 四、定性分析与可解释性
- 生成查询具有可解释性：查询内容直接反映用户兴趣（如“无线鼠标”、“化妆盘”）。
- 适应性强：能根据用户历史兴趣的集中或分散程度，自适应生成不同粒度的查询。
- 支持冷启动：生成的查询可用于检索新商品，缓解冷启动问题。

---

### 总结
GPT4Rec 通过生成式查询 + 检索的方式，将推荐任务转化为语言生成问题，既能利用商品内容信息，又能生成可解释的用户兴趣表示。
,支持替换更先进的生成模型或检索引擎，为个性化推荐提供了新的思路。